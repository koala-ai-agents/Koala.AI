# Auto-generated Airflow DAG from koala flow: koala_web_search
# Generated by Kola-AI AirflowExecutor (Dynamic Version)
# This DAG imports tools dynamically - no embedded code

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from typing import Dict, Any
import sys
from pathlib import Path

# Add cookbook to path for importing tools
cookbook_path = Path(__file__).parent.parent / "cookbook"
if cookbook_path.exists() and str(cookbook_path) not in sys.path:
    sys.path.insert(0, str(cookbook_path))

# Also try current directory
dags_path = Path(__file__).parent
if str(dags_path) not in sys.path:
    sys.path.insert(0, str(dags_path))

# Dynamic imports of tools
TOOL_REGISTRY = {}

# Import tools from source modules
try:
    import web_search_agent
    TOOL_REGISTRY['llm_summarize'] = web_search_agent.llm_summarize
    TOOL_REGISTRY['scrape_urls'] = web_search_agent.scrape_urls
    TOOL_REGISTRY['format_output'] = web_search_agent.format_output
    TOOL_REGISTRY['extract_context'] = web_search_agent.extract_context
    TOOL_REGISTRY['web_search'] = web_search_agent.web_search
    # Load environment variables if available
    if hasattr(web_search_agent, '_load_env'):
        web_search_agent._load_env()
        print(f'‚úÖ Loaded environment from web_search_agent')
except ImportError as e:
    print(f'Warning: Could not import web_search_agent: {e}')
    import traceback
    traceback.print_exc()


def execute_kola_step(**context):
    """Execute a Kola step using dynamically imported tools."""
    step_id = context['params']['step_id']
    action = context['params']['action']
    args = context['params']['args']

    # Get tool function from registry
    if action not in TOOL_REGISTRY:
        available = list(TOOL_REGISTRY.keys())
        raise ValueError(f"Tool '{action}' not found. Available: {available}")

    func = TOOL_REGISTRY[action]

    # Resolve $result references via XCom
    resolved_args = {}
    for key, value in args.items():
        if isinstance(value, str) and value.startswith("$result."):
            ref_parts = value.split("$result.", 1)[1].split(".", 1)
            upstream_step = ref_parts[0]
            ti = context['ti']
            result = ti.xcom_pull(task_ids=upstream_step)

            if len(ref_parts) > 1:
                for key_part in ref_parts[1].split("."):
                    result = result[key_part] if isinstance(result, dict) else getattr(result, key_part)
                resolved_args[key] = result
            else:
                resolved_args[key] = result
        elif isinstance(value, str) and "<<FROM_DAG_CONFIG>>" in value:
            # Get question from dag_run.conf
            dag_run = context.get('dag_run')
            if dag_run and hasattr(dag_run, 'conf') and dag_run.conf:
                question = dag_run.conf.get('question')
                if question:
                    print(f"üìù Using question from config: {question}")
                    # Replace the placeholder with actual question
                    resolved_args[key] = value.replace("<<FROM_DAG_CONFIG>>", question)
                else:
                    print(f"‚ö†Ô∏è  No 'question' in config, using default")
                    resolved_args[key] = "What is AI?"
            else:
                print(f"‚ö†Ô∏è  No DAG run config, using default")
                resolved_args[key] = "What is AI?"
        else:
            resolved_args[key] = value

    # Execute tool
    return func(**resolved_args)

# Define DAG
default_args = {
    'owner': 'kola',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(seconds=30),
}

with DAG(
    dag_id='koala_web_search',
    default_args=default_args,
    description='Kola flow: koala_web_search',
    schedule=None,
    catchup=False,
    tags=['kola-generated'],
) as dag:

    search = PythonOperator(
        task_id='search',
        python_callable=execute_kola_step,
        params={
            'step_id': 'search',
            'action': 'web_search',
            'args': {"query": "<<FROM_DAG_CONFIG>>", "max_results": 3},
        },
    )

    scrape = PythonOperator(
        task_id='scrape',
        python_callable=execute_kola_step,
        params={
            'step_id': 'scrape',
            'action': 'scrape_urls',
            'args': {"search_results": "$result.search", "max_pages": 2},
        },
    )

    extract = PythonOperator(
        task_id='extract',
        python_callable=execute_kola_step,
        params={
            'step_id': 'extract',
            'action': 'extract_context',
            'args': {"search_results": "$result.scrape"},
        },
    )

    summarize = PythonOperator(
        task_id='summarize',
        python_callable=execute_kola_step,
        params={
            'step_id': 'summarize',
            'action': 'llm_summarize',
            'args': {"question": "<<FROM_DAG_CONFIG>>", "context": "$result.extract"},
        },
    )

    format = PythonOperator(
        task_id='format',
        python_callable=execute_kola_step,
        params={
            'step_id': 'format',
            'action': 'format_output',
            'args': {"summary": "$result.summarize", "question": "<<FROM_DAG_CONFIG>>"},
        },
    )

    # Task dependencies
    search >> scrape
    scrape >> extract
    extract >> summarize
    summarize >> format
